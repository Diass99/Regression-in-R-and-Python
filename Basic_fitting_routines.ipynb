{"cells":[{"cell_type":"markdown","metadata":{"id":"5S6LR1tfw0Qy"},"source":["---\n","title: \"Fitting Data - Basic implementation of Python packages\"\n","date: 2020-07-17\n","tags: [\"data science\"]\n","draft: false\n","---"]},{"cell_type":"markdown","metadata":{"id":"O6BgXOPmw0Q1"},"source":["In this notebook I show some basic implementation of different Python packages for data fitting. The idea is to learn the different options there are out there so the reader can then study them in more detail if needed.\n","\n","This notebook can be opened on [google colab](https://colab.research.google.com/) or [binder](https://mybinder.org/). If for some reason there is a package missing, you will need to manually install it by running `!pip install <package>` in a cell.\n","\n","To open this notebook on google colab, click in the following icon: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/temuller/personal_website/blob/master/content/post/fitting_data/basic_fitting_routines.ipynb)\n","\n","To open this notebook on binder, click in the following icon: [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/temuller/personal_website/master?filepath=content%2Fpost%2Ffitting_data%2Fbasic_fitting_routines.ipynb)"]},{"cell_type":"code","source":["!pip install lmfit\n","!pip install emcee\n","!pip install iminuit\n","!pip install corner"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L0WaWKLoxVkp","outputId":"d776aa0b-9a3a-4faf-96a2-2d39b1037ba8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting lmfit\n","  Downloading lmfit-1.2.0-py3-none-any.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting asteval>=0.9.28\n","  Downloading asteval-0.9.29-py3-none-any.whl (18 kB)\n","Requirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.9/dist-packages (from lmfit) (1.10.1)\n","Collecting uncertainties>=3.1.4\n","  Downloading uncertainties-3.1.7-py2.py3-none-any.whl (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.4/98.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.9/dist-packages (from lmfit) (1.22.4)\n","Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from uncertainties>=3.1.4->lmfit) (0.18.3)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rL1_XlLRw0Q2"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import pandas as pd\n","\n","import scipy\n","import lmfit\n","import emcee\n","#import pymc3  # borken installation?\n","import pystan\n","import iminuit\n","from iminuit.util import describe, make_func_code\n","\n","from keras.layers import Dense, Activation\n","from keras.models import Sequential\n","\n","from multiprocessing import Pool\n","import corner\n","\n","sns.set(context='talk', style='white')\n","%config InlineBackend.figure_format = 'retina'\n","\n","np.random.seed(32)"]},{"cell_type":"markdown","metadata":{"id":"KxS9e_XHw0Q6"},"source":["This example, which represents data taken from a line, was taken from the `emcee` documentation.\n","\n","To avoid correlation between parameters in this case, one would need to shift the x-axis by the mean value, but I will ommit that in here for simplicity. I will only show how to implement the different packages."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_tP0aeSNw0Q7"},"outputs":[],"source":["# Choose the \"true\" parameters.\n","m_true = -0.9594\n","b_true = 4.294\n","f_true = 0.534\n","\n","# Generate some synthetic data from the model.\n","N = 50\n","x = np.sort(10 * np.random.rand(N))\n","yerr = 0.1 + 0.5 * np.random.rand(N)\n","y = m_true * x + b_true\n","y += np.abs(f_true * y) * np.random.randn(N)\n","y += yerr * np.random.randn(N)\n","\n","plt.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=0)\n","x0 = np.linspace(0, 10, 500)\n","plt.plot(x0, m_true * x0 + b_true, \"k\", alpha=0.3, lw=3)\n","plt.xlim(0, 10)\n","plt.xlabel(\"x\")\n","plt.ylabel(\"y\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"SnnV2Wmxw0RA"},"source":["## scipy - minimize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NQzI5Og-w0RB"},"outputs":[],"source":["def log_likelihood(theta, x, y, yerr):\n","    m, b = theta\n","    model = m*x + b\n","    sigma2 = yerr**2\n","    return np.sum((y - model)**2 / sigma2)\n","\n","p0 = np.array([m_true, b_true]) + 0.1 * np.random.randn(2)\n","results = scipy.optimize.minimize(log_likelihood, p0, args=(x, y, yerr))\n","\n","m_pred, b_pred = results.x\n","\n","y_pred = m_pred*x0 + b_pred\n","y_true = m_true*x0 + b_true\n","\n","plt.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=0)\n","plt.plot(x0, y_true, \"k\", alpha=0.3, lw=3, label=\"truth\")\n","plt.plot(x0, y_pred, \":k\", label=\"fit\")\n","plt.legend(fontsize=14)\n","plt.xlim(0, 10)\n","plt.xlabel(\"x\")\n","plt.ylabel(\"y\")\n","plt.show()\n","\n","print(f'm = {m_pred:.4f} (m_true = {m_true})')\n","print(f'b = {b_pred:.3f} (b_true = {b_true})')"]},{"cell_type":"markdown","metadata":{"id":"IkIynrmrw0RF"},"source":["## scipy - curve_fit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hm7BcQ1_w0RG"},"outputs":[],"source":["def function(x, m, b):\n","    model = m*x + b\n","    return model\n","\n","p0 = np.array([m_true, b_true]) + 0.1 * np.random.randn(2)\n","pfit, pcov = scipy.optimize.curve_fit(function, x, y, p0=p0, sigma=yerr)\n","\n","m_pred, b_pred = pfit\n","m_std, b_std = np.sqrt(pcov[0, 0]), np.sqrt(pcov[1, 1])\n","\n","y_pred = m_pred*x0 + b_pred\n","y_true = m_true*x0 + b_true\n","\n","plt.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=0)\n","plt.plot(x0, y_true, \"k\", alpha=0.3, lw=3, label=\"truth\")\n","plt.plot(x0, y_pred, \":k\", label=\"fit\")\n","plt.legend(fontsize=14)\n","plt.xlim(0, 10)\n","plt.xlabel(\"x\")\n","plt.ylabel(\"y\")\n","plt.show()\n","\n","print(f'm = {m_pred:.4f} +/- {m_std:.4f} (m_true = {m_true})')\n","print(f'b = {b_pred:.3f} +/- {b_std:.3f} (b_true = {b_true})')"]},{"cell_type":"markdown","metadata":{"id":"Z4d4TSkqw0RI"},"source":["## scipy - leastsq"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nrk98w9Nw0RK"},"outputs":[],"source":["def residual_function(theta, x, y, yerr):\n","    m, b = theta\n","    model = m*x + b\n","    return (model - y)/yerr\n","\n","p0 = np.array([m_true, b_true]) + 0.1 * np.random.randn(2)\n","pfit, pcov, infodict, errmsg, success = scipy.optimize.leastsq(residual_function, p0, \n","                                                               args=(x, y, yerr), \n","                                                               full_output=1)\n","\n","m_pred, b_pred = pfit\n","try:\n","    m_std, b_std = np.sqrt(pcov[0, 0]), np.sqrt(pcov[1, 1])\n","except:\n","    m_std = b_std = np.inf\n","\n","y_pred = m_pred*x0 + b_pred\n","y_true = m_true*x0 + b_true\n","\n","plt.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=0)\n","plt.plot(x0, y_true, \"k\", alpha=0.3, lw=3, label=\"truth\")\n","plt.plot(x0, y_pred, \":k\", label=\"fit\")\n","plt.legend(fontsize=14)\n","plt.xlim(0, 10)\n","plt.xlabel(\"x\")\n","plt.ylabel(\"y\")\n","plt.show()\n","\n","print(f'm = {m_pred:.4f} +/- {m_std:.4f} (m_true = {m_true})')\n","print(f'b = {b_pred:.3f} +/- {b_std:.3f} (b_true = {b_true})')"]},{"cell_type":"markdown","metadata":{"id":"eroA9C7qw0RL"},"source":["## lmfit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MYuDx76vw0RM"},"outputs":[],"source":["def residual_function(params, x, y, yerr):\n","    m, b = params['m'].value, params['b'].value\n","    model = m*x + b\n","    return ((model - y)/yerr)**2\n","\n","p0 = np.array([m_true, b_true]) + 0.1 * np.random.randn(2)\n","params = lmfit.Parameters()\n","params.add('m', value=p0[0])\n","params.add('b', value=p0[1])\n","results = lmfit.minimizer.minimize(residual_function, params, args=(x, y, yerr)\n","                                   , method='lbfgsb')\n","\n","m_pred, b_pred = results.params['m'].value, results.params['b'].value\n","m_std, b_std = results.params['m'].stderr, results.params['b'].stderr\n","if m_std is None and b_std is None:\n","    m_std = b_std = np.inf\n","\n","y_pred = m_pred*x0 + b_pred\n","y_true = m_true*x0 + b_true\n","\n","plt.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=0)\n","plt.plot(x0, y_true, \"k\", alpha=0.3, lw=3, label=\"truth\")\n","plt.plot(x0, y_pred, \":k\", label=\"fit\")\n","plt.legend(fontsize=14)\n","plt.xlim(0, 10)\n","plt.xlabel(\"x\")\n","plt.ylabel(\"y\")\n","plt.show()\n","\n","print(f'm = {m_pred:.4f} +/- {m_std:.4f} (m_true = {m_true})')\n","print(f'b = {b_pred:.3f} +/- {b_std:.3f} (b_true = {b_true})')"]},{"cell_type":"markdown","metadata":{"id":"89iC0bmqw0RR"},"source":["## iminuit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RJORHRVVw0RS"},"outputs":[],"source":["from iminuit import Minuit\n","\n","def line(m, b, x, y):\n","    return m*x + b\n","\n","def residual_function(m, b):\n","    #b, m = theta\n","    model = line(m, b, x, y)\n","    return np.sum(((model - y)/yerr)**2)\n","\n","minu = Minuit(residual_function)\n","\n","minu.migrad()  # run optimiser\n","minu.hesse()   # run covariance estimator\n","minu.minos()  # run minos estimator\n","\n","m_pred, b_pred = minu.values.values()\n","m_std, b_std = minu.errors.values()\n","m_std_max, b_std_max, m_std_min, b_std_min = minu.merrors.values()\n","\n","y_pred = m_pred*x0 + b_pred\n","y_true = m_true*x0 + b_true\n","\n","plt.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=0)\n","plt.plot(x0, y_true, \"k\", alpha=0.3, lw=3, label=\"truth\")\n","plt.plot(x0, y_pred, \":k\", label=\"fit\")\n","plt.legend(fontsize=14)\n","plt.xlim(0, 10)\n","plt.xlabel(\"x\")\n","plt.ylabel(\"y\")\n","plt.show()\n","\n","print('Hesse')\n","print(f'm = {m_pred:.4f} +/- {m_std:.4f} (m_true = {m_true})')\n","print(f'b = {b_pred:.3f} +/- {b_std:.3f} (b_true = {b_true})')\n","print('Minos')\n","print(f'm = {m_pred:.4f} +/- ({m_std_min:.4f}, {m_std_max:.4f}) (m_true = {m_true})')\n","print(f'b = {b_pred:.3f} +/- ({b_std_min:.3f}, {b_std_max:.3f}) (b_true = {b_true})')\n","\n","minu.draw_mncontour('m', 'b', nsigma=3)"]},{"cell_type":"markdown","metadata":{"id":"oLaSXaw5w0RT"},"source":["___\n","___\n","# MCMC inference\n","\n","There are a couple of packages for plotting the samples with these methods. One is `corner`, which is well known by most people I would say, and the other one, which I actually prefer and use here, is `chainconsumer`."]},{"cell_type":"markdown","metadata":{"id":"FT9GIwYlw0RU"},"source":["___\n","## emcee"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UMJEMWgew0RV"},"outputs":[],"source":["def log_like(theta, x, y, yerr):\n","    m, b = theta\n","    model = m*x + b\n","    sigma2 = yerr ** 2\n","    return -0.5 * np.sum((y - model)**2/sigma2 + np.log(sigma2))\n","\n","def log_prior(theta):\n","    m, b = theta\n","    if -5.0 < m < 0.5 and 0.0 < b < 10.0:\n","        return 0.0\n","    return -np.inf\n","\n","def log_probability(theta, x, y, yerr):\n","    lp = log_prior(theta)\n","    if not np.isfinite(lp):\n","        return -np.inf\n","    return lp + log_like(theta, x, y, yerr)\n","\n","pos = np.array([m_true, b_true]) + 1e-4*np.random.randn(32, 2)\n","nwalkers, ndim = pos.shape\n","\n","with Pool() as pool:\n","    sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability, \n","                                    args=(x, y, yerr), pool=pool)\n","    sampler.run_mcmc(pos, 4000, progress=True)\n","\n","samples = sampler.chain[:, 1000:, :].reshape((-1, ndim))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JoEaZtt1w0RW"},"outputs":[],"source":["fig, axes = plt.subplots(ndim, figsize=(10, 5), sharex=True)\n","labels = [\"m\", \"b\"]\n","\n","for i in range(ndim):\n","    ax = axes[i]\n","    ax.plot(samples[:, i], \"k\", alpha=0.6)\n","    ax.set_xlim(0, len(samples))\n","    ax.set_ylabel(labels[i])\n","    ax.yaxis.set_label_coords(-0.1, 0.5)\n","\n","axes[-1].set_xlabel(\"step number\");\n","\n","fig = corner.corner(\n","    samples, labels=labels, truths=[m_true, b_true]\n",");"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"16yT2Kp5w0RX"},"outputs":[],"source":["m_mcmc = np.percentile(samples[:, 0], [16, 50, 84])\n","b_mcmc = np.percentile(samples[:, 1], [16, 50, 84])\n","m_pred, b_pred = m_mcmc[1], b_mcmc[1]\n","m_std_min, m_std_max = np.diff(m_mcmc)\n","b_std_min, b_std_max = np.diff(b_mcmc)\n","\n","y_pred = m_pred*x0 + b_pred\n","y_true = m_true*x0 + b_true\n","\n","plt.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=0)\n","plt.plot(x0, y_true, \"k\", alpha=0.3, lw=3, label=\"truth\")\n","plt.plot(x0, y_pred, \":k\", label=\"fit\")\n","plt.legend(fontsize=14)\n","plt.xlim(0, 10)\n","plt.xlabel(\"x\")\n","plt.ylabel(\"y\")\n","plt.show()\n","\n","print(f'm = {m_pred:.4f} +/- ({m_std_min:.4f}, {m_std_max:.4f}) (m_true = {m_true})')\n","print(f'b = {b_pred:.4f} +/- ({b_std_min:.4f}, {b_std_max:.4f}) (b_true = {b_true})')"]},{"cell_type":"markdown","metadata":{"id":"SSFIYUlxw0RZ"},"source":["## pystan"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NRPVl6BZw0RZ"},"outputs":[],"source":["model = \"\"\"\n","        data {\n","            int<lower=0> N;\n","            vector[N] x;\n","            vector[N] y;\n","        }\n","        parameters {\n","            real m;\n","            real b;\n","            real<lower=0> sigma;\n","        }\n","        model {\n","            y ~ normal(b + m*x, sigma);\n","        }\n","        \"\"\"\n","\n","data = {'N': len(x), 'x': x, 'y': y}\n","\n","# Compile the model\n","sm = pystan.StanModel(model_code=model)\n","\n","# Train the model and generate samples\n","fit = sm.sampling(data=data, iter=1000, chains=4, warmup=500, thin=1, seed=101)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U3BJ6mzNw0Ra"},"outputs":[],"source":["summary_dict = fit.summary()\n","df = pd.DataFrame(summary_dict['summary'], \n","                  columns=summary_dict['summary_colnames'], \n","                  index=summary_dict['summary_rownames'])\n","\n","m_pred, b_pred = df['mean']['m'], df['mean']['b']\n","m_std, b_std = df['sd']['m'], df['sd']['b']\n","\n","# Extracting traces\n","m_trace = fit['m']\n","b_trace = fit['b']\n","sigma = fit['sigma']\n","lp = fit['lp__']\n","\n","y_pred = m_pred*x0 + b_pred\n","y_true = m_true*x0 + b_true\n","\n","plt.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=0)\n","plt.plot(x0, y_true, \"k\", alpha=0.3, lw=3, label=\"truth\")\n","plt.plot(x0, y_pred, \":k\", label=\"fit\")\n","plt.legend(fontsize=14)\n","plt.xlim(0, 10)\n","plt.xlabel(\"x\")\n","plt.ylabel(\"y\")\n","plt.show()\n","\n","print(f'm = {m_pred:.4f} +/- {m_std:.4f} (m_true = {m_true})')\n","print(f'b = {b_pred:.3f} +/- {b_std:.3f} (b_true = {b_true})')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SOZjpQNSw0Rc"},"outputs":[],"source":["samples = np.array([m_trace, b_trace]).T\n","                   \n","fig, axes = plt.subplots(ndim, figsize=(10, 5), sharex=True)\n","labels = [\"m\", \"b\"]\n","\n","for i in range(ndim):\n","    ax = axes[i]\n","    ax.plot(samples[:, i], \"k\", alpha=0.6)\n","    ax.set_xlim(0, len(samples))\n","    ax.set_ylabel(labels[i])\n","    ax.yaxis.set_label_coords(-0.1, 0.5)\n","\n","axes[-1].set_xlabel(\"step number\");\n","\n","fig = corner.corner(\n","    samples, labels=labels, truths=[m_true, b_true]\n",");"]},{"cell_type":"markdown","metadata":{"id":"NTvCu4Gjw0Rd"},"source":["## pymc3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jYC9eKQ5w0Rh"},"outputs":[],"source":["basic_model = pymc3.Model()\n","\n","with basic_model:\n","    \n","    p0 = np.array([m_true, b_true]) + 0.1 * np.random.randn(2)\n","    # Priors for unknown model parameters\n","    m = pymc3.Normal('m', mu=p0[0], sigma=2)\n","    b = pymc3.Normal('b', mu=p0[1], sigma=5)\n","    sigma = pymc3.HalfNormal('sigma', sigma=1)\n","\n","    # Expected value of outcome\n","    model =m*x + b\n","\n","    # Likelihood (sampling distribution) of observations\n","    Y_obs = pymc3.Normal('Y_obs', mu=model, sigma=sigma, observed=y)\n","    \n","map_estimate = pymc3.find_MAP(model=basic_model)\n","\n","with basic_model:\n","   # instantiate sampler\n","    step = pymc3.Slice()\n","\n","    # draw 5000 posterior samples\n","    trace = pymc3.sample(5000, step=step)\n","\n","pymc3.traceplot(trace);\n","pymc3.summary(trace).round(2)"]},{"cell_type":"markdown","metadata":{"id":"kRL1dl_hw0Ri"},"source":["## Other packages\n","\n","There are other packages for performing MCMC inference like: `Pyro/NumPyro`, `mici`, `TensorFlow Probability` and `Sampyl` (I might be missing a couple though). Feel free to check those as well."]},{"cell_type":"markdown","metadata":{"id":"KlNxl4uQw0Rj"},"source":["___\n","___\n","# Artificial Neural Networks (ANN) regression\n","\n","The ANN will fit the data without a given model. A proper fit would require training sets, testing sets and cross validation, but here only the most basic implementation is shown. There is much more you can do with ANN."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JzSr50UUw0Rj"},"outputs":[],"source":["# NN model\n","model = Sequential()\n","model.add(Dense(32, activation = 'relu'))\n","model.add(Dense(units = 32, activation = 'relu'))\n","model.add(Dense(units = 32, activation = 'relu'))\n","model.add(Dense(units = 1))\n","\n","# Compiling the ANN\n","model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n","\n","model.fit(x[:, None], y, batch_size = 10, epochs = 100, verbose=0)\n","\n","y_pred = model.predict(x[:, None])\n","y_true = m_true*x0 + b_true\n","\n","plt.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=0)\n","plt.plot(x0, y_true, \"k\", alpha=0.3, lw=3, label=\"truth\")\n","#plt.plot(x0, y_pred, \":k\", label=\"fit\")\n","plt.plot(x[:, None], y_pred, \":k\", label=\"fit\")\n","plt.legend(fontsize=14)\n","plt.xlim(0, 10)\n","plt.xlabel(\"x\")\n","plt.ylabel(\"y\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9tJBwnXw0Rk"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"provenance":[{"file_id":"1A26uV-ugX_dvIKLePJBsogeR6a6K6ntz","timestamp":1654539422605},{"file_id":"https://github.com/temuller/personal_website/blob/master/content/post/fitting_data/basic_fitting_routines.ipynb","timestamp":1654263081514}]}},"nbformat":4,"nbformat_minor":0}